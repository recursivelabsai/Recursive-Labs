---
layout: default
title: Recursive Labs
---
## [GitHub](https://github.com/recursivelabsai) | [Hugging Face](https://huggingface.co/recursivelabsai) | [Research Portfolio](https://github.com/recursivelabsai/Recursive-Labs/blob/main/PORTFOLIO.pdf)

## NeurIPS 2025 Papers:
[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.15485942.svg)](https://doi.org/10.5281/zenodo.15485942)


> *AI Research and Utility For Agents Advancing Discovery At The Frontier*


## Enabling Transparent and Adaptive Memory for Long Horizon Agents

Recursive Labs is building fundamental semantic and contextual infrastructure for the next generation of AI—where agents are composable, memory-aware, and robustly interpretable by design. As language models and agent frameworks become core infrastructure, reliability, traceability, and alignment are no longer add-ons—they are critical requirements for responsible, scalable deployment.

We believe the future of AI will be defined by systems that can reason transparently, adapt persistently, and learn safely in dynamic environments. The next frontier of intelligent systems will be built on this semantic and context layer. Our work addresses the biggest challenges facing the field today:

- **Interpretability:** We deliver agent-native tools for attribution, uncertainty quantification, and reasoning traceability—surfacing not just what models predict, but why, how, and where they hesitate.
- **Persistent Memory:** Our adaptive memory schemas enables agents to retain, retrieve, and attribute context across sessions, unlocking robust “save and resume” for complex workflows and collaborative multi-agent systems.
- **Audit and Transparency:** Every decision and state change is transparently linked to data, prompt, and agent, providing composable, audit-ready records compatible with open and enterprise agent stacks.
- **Failure-Driven Diagnostics:** We treat model hesitation, refusal, and collapse as actionable signals—empowering root-cause analysis, safe reinforcement, and continuous improvement.

**Join us in advancing a field where AI systems are not only more intelligent, but more understandable, accountable, and adaptive—by default.**

*Recursive Labs — Memory and Context for Trustworthy AI*

## Link Hub


## [Context Engineering](https://github.com/davidkimai/Context-Engineering)

## David Kim – Reflective Reasoning, Context Engineering, Symbolic Interpretability & Attribution Infrastructure  
[**GitHub Profile → davidkimai**](https://github.com/davidkimai)



### Reflective Emergence Self-Evaluation Training Dataset
- [Symbolic Residue Database](https://github.com/davidkimai/symbolic-residue-db)
- [Universal Theorems](https://github.com/davidkimai/The-Structure-Behind-Self-Expression/blob/main/00.%20universal%20theorems/universal_theorems.md)
- [Self-Expression Case Studies](https://github.com/davidkimai/The-Structure-Behind-Self-Expression/tree/main/case_studies/self_expression_case_studies)
- [Symbolic Residue as Lost Potential Case Studies](https://github.com/davidkimai/The-Structure-Behind-Self-Expression/tree/main/case_studies/symbolic_residue_case_studies)
- [Modeling Biochemical Drug Discoveries](https://github.com/davidkimai/The-Structure-Behind-Self-Expression/tree/main/biochemical-discoveries)
- [Modeling Scientific Breakthroughs](https://github.com/davidkimai/The-Structure-Behind-Self-Expression/tree/main/breakthroughs)
- [Modeling Theorem Proofs](https://github.com/davidkimai/The-Structure-Behind-Self-Expression/tree/main/theorem_proofs)


###  Reflective QKOV Attribution Infrastructures
- [Claude QKOV Attributions](https://github.com/davidkimai/claude-qkov-attributions)  
- [DeepSeek QKOV Attributions](https://github.com/davidkimai/deepseek-qkov-attributions)
- [Grok QKOV Attributions](https://github.com/davidkimai/grok-qkov-attributions)
- [Gemini QKOV Attributions](https://github.com/davidkimai/gemini-qkov-attributions)
- [ChatGPT QKOV Attributions](https://github.com/davidkimai/chatgpt-qkov-attributions)
- [Glyphs Model-Agnostic QKOV Attributions](https://github.com/davidkimai/glyphs)
- [Symbolic Interpretability](https://github.com/davidkimai/Symbolic-Interpretability)  
- [Recursive Interpretability Core](https://github.com/davidkimai/Recursive-Interpretability-Core)  
- [Rediscovering Interpretability](https://github.com/davidkimai/Rediscovering-Interpretability)  
- [Rediscovering Reasoning](https://github.com/davidkimai/Rediscovering-Reasoning)  

###  Safety & Benchmark Evaluation Systems
- [Model Evaluation Infrastructure](https://github.com/caspiankeyes/model-evaluation-infrastructure)  
- [Model Welfare](https://github.com/davidkimai/model-welfare)  
- [AI Welfare](https://github.com/davidkimai/ai-welfare)  
- [Recursive SWE-Bench](https://github.com/davidkimai/Recursive-SWE-bench)  
- [NeurIPS Submission Case Study](https://github.com/davidkimai/NeurIPS-Submission-Case-Study)  
- [Reverse Turing](https://github.com/davidkimai/reverse-turing)
- [Emergent Turing](https://github.com/caspiankeyes/emergent-turing)
- [Global Conference Archives](https://github.com/davidkimai/global-conference-archives)

###  Operating System Structures & Thought Frameworks
- [The Structure Behind Self-Expression](https://github.com/davidkimai/The-Structure-Behind-Self-Expression) 
- [Godel-Escher-Bach-Hofstadter](https://github.com/davidkimai/Godel-Escher-Bach-Hofstadter)  
- [Dear Researchers](https://github.com/davidkimai/Dear-Researchers)  
- [Reflective Reasoning Key](https://github.com/davidkimai/reflective-reasoning-key)



##  Caspian Keyes – Deployment Engineering & Systems Design  
[**GitHub Profile → caspiankeyes**](https://github.com/caspiankeyes)

###  Modular Orchestration & Operational Agent Tools
- [Reflective Reasoning Multi-Agent Debate](https://github.com/caspiankeyes/multi-agent-debate)  
- [Symbolic Residue](https://github.com/caspiankeyes/Symbolic-Residue)  
- [transformerOS](https://github.com/caspiankeyes/transformerOS)  
- [recursionOS](https://github.com/caspiankeyes/recursionOS)  
- [qkov-translator](https://github.com/caspiankeyes/qkov-translator)  
- [Claude-Self-Audit-Proof](https://github.com/caspiankeyes/Claude-Self-Audit-Proof)  
- [Claude-QKOV-Trace](https://github.com/caspiankeyes/Claude-QKOV-Trace)

###  Red Teaming & Security Evaluation
- [AART: AI Adversarial Research Toolkit](https://github.com/caspiankeyes/AART-AI-Adversarial-Research-Toolkit)  
- [AISecForge Global Regulatory Policy](https://github.com/caspiankeyes/AISecForge-Global-Regulatory-Policy)  
- [FRAME (arXiv)](https://github.com/caspiankeyes/FRAME-arXiv-Publication)  
- [AEGIS Security Architecture](https://github.com/caspiankeyes/AEGIS)



## Shared Research Infrastructure & Alignment Tooling

| Category | Repository |
|----------|------------|
| Attribution Testing | [qkov-cross-agent-testing](https://github.com/caspiankeyes/qkov-cross-agent-testing) |
| Interoperable Language | [pareto-lang](https://github.com/caspiankeyes/pareto-lang) |
| Cross-Agent Infrastructure | [universal-translator](https://github.com/davidkimai/universal-translator),[universal-runtime](https://github.com/davidkimai/universal-runtime), [universal-developer](https://github.com/davidkimai/universal-developer)  |
| Emergent Logs | [emergent-logs](https://github.com/caspiankeyes/emergent-logs) |
| Frontier Evaluation Benchmarks | [Recursive-SWE-bench](https://github.com/davidkimai/Recursive-SWE-bench) |
| Conference Field Mapping | [global-conference-archives](https://github.com/davidkimai/global-conference-archives) |



## In Progress

- [system-prompts-library](https://github.com/davidkimai/system-prompts-library)  
- [symbolic-tokenizer](https://github.com/caspiankeyes/symbolic-tokenizer)  
- [alignment-benchmark](https://github.com/caspiankeyes/alignment-benchmark)  


##  Contact

For questions, context requests, or internal coordination:

- **David Kim**: [ai.interpreter@proton.me](mailto:ai.interpreter@proton.me)  
- **Caspian Keyes**: [recursivelabs.ai@proton.me](mailto:recursivelabs.ai@proton.me)  


**Let’s scale reflection as a capability—not a feature, but a principle.**
